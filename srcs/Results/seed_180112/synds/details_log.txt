Cut-off: 0.55
Network architecture:
Input layer: 31 units, activation: relu
Hidden layer: 30 units, activation: relu
Hidden layer: 30 units, activation: relu
Output layer: 4 units, activation: softmax