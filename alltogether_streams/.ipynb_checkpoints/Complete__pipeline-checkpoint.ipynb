{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TreeStructure DS creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![BinaryTree](tree.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example\n",
    "\n",
    "0. : _si muove?_\n",
    "1. : _nuota?_\n",
    "2. : _corteccia?_\n",
    "3. : _mammifero?_\n",
    "4. : _vertebrato?_\n",
    "5. : _conifera?_\n",
    "6. : _petali?_\n",
    "7. : Balena\n",
    "8. : Salmone\n",
    "9. : Cane\n",
    "10. : Farfalla\n",
    "11. : Larice\n",
    "12. : Betulla\n",
    "13. : Rosa\n",
    "14. : Gramigna\n",
    "\n",
    "Quindi un _pattern_ è dato dalla raccolta di **tutti** i valori della v.c. binaria presso tutti i nodi dell'albero, cioè le _features_. Come esempio molto semplice, si associano ai nodi **non foglie** delle regole decisionali, mentre ai restanti si associa un elemento di una categoria. Questo modello è _molto_ approssimativo in quanto una struttura più complessa dell'albero (diramazione non constante, struttura non perfetta e completa) dovrebbe essere usata.\n",
    "\n",
    "Nel codice seguente le scelte fatte nella generazione dei data item sono:\n",
    "\n",
    "0. La soglia probabilistica $\\epsilon$ viene stabilita a priori, di piccolo valore\n",
    "1. Il nodo root è una vc che assume i valori $\\pm 1$ con $p = 0.5$\n",
    "2. I children del nodo root assumono il valore $+1$ o $-1$ in modo mutuamente esclusivo, quale dei due eredita il valore positivo viene deciso in base all'estrazione di un campione $p \\sim U([0,1])$: il primo child riceve il valore $+1$ con probabilità $p = 0.5$\n",
    "3. Dal terzo livello (i primi nipoti del nodo root), tutta la progenie del child di root che ha assunto valore $-1$ deve altrettanto assumere il valore $-1$, quindi scorrendo sui nodi di tutti i livelli, il flip di valore viene preso in considerazione solo nel momento in cui il nodo in esame ha valore $1$. Questo garantisce che l'item finale (raccolta di tutti i valori presso tutti i nodi) possa essere univocamente identificato.\n",
    "\n",
    "Nella seconda cella di codice, la variabile `lev` identifica il livello del quale considerare i nodi. Ad esempio, anche in riferimento alla Figura sopra, `lev = 3` stabilisce che la granulometria del data set sia quella di cui il livello terminale, quindi le leaves. Quindi il sistema di apprendimento successivamente impiegato impara a riconoscere le distinzioni più fine.\n",
    "\n",
    "Importante notare che questa distinzione si fa considerando **tutti i nodi FINO** a quelli di cui il livello selezionato, quindi tutta la genealogia dei nodi del livello scelto deve essere uguale affinché due pattern appartengano alla stessa classe. Se, al contrario, considerassimo solo nodi di un certo livello, data l'estrazione aleatoria del valore di root e del passaggio del valore $+1$ ai primi due children, potremmo avere che due pattern appartengono alla stessa classe, secondo i nodi del livello scelto, ma avere valore opposto del nodo root, il che vorrebbe dire che _una pianta può nuotare/volare_.\n",
    " \n",
    "Maggiore è il livello, maggiore è il numero di categorie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import random\n",
    "\n",
    "\n",
    "class BinaryTreeDataSet:\n",
    "    \n",
    "    def __init__(self,Bf,D,M):\n",
    "                              # Bf : branching factor\n",
    "                              # D : livelli dell'albero\n",
    "        self.N = Bf**(D) - 1  # tutti i nodi\n",
    "        self.n = Bf**(D-1) -1 # tutti i nodi NON foglie\n",
    "        self.P = Bf**(D-1)    # tutti i nodi foglie\n",
    "        self.M = M            # quanti pattern (data items)\n",
    "        \n",
    "        print('\\nTree characts:\\n')\n",
    "        print('   Nodes (feats) : N = ',self.N)\n",
    "        print('Nodes NOT leaves : n = ',self.n)\n",
    "        print('    Nodes leaves : P = ',self.P)\n",
    "        print('        Patterns : M = ',self.M)\n",
    "    #end\n",
    "\n",
    "    def patternGenerator(self):\n",
    "        \n",
    "        N = self.N\n",
    "        n = self.n\n",
    "    \n",
    "        tree = np.zeros(N)\n",
    "        outcomes = [-1,1]\n",
    "        e = 0.5\n",
    "        tree[0] = outcomes[random.randint(0,2)]\n",
    "        \n",
    "        p = random.rand()\n",
    "        if (p >= 0.5):\n",
    "            tree[1] = tree[0]\n",
    "            tree[2] = (-1.) * tree[0]\n",
    "        else: \n",
    "            tree[1] = (-1.) * tree[0]\n",
    "            tree[2] = tree[0]\n",
    "        #endif\n",
    "        \n",
    "        for k in range(1,n):\n",
    "            if (tree[k] == 1):\n",
    "                p = random.rand()\n",
    "                if (p > e):\n",
    "                    tree[2*k + 1] = tree[k]\n",
    "                    tree[2*k + 2] = (-1.) * tree[k]\n",
    "                else:\n",
    "                    tree[2*k + 1] = (-1.) * tree[k]\n",
    "                    tree[2*k + 2] = tree[k]\n",
    "                #endif\n",
    "            else:\n",
    "                tree[2*k + 1] = -1\n",
    "                tree[2*k + 2] = -1\n",
    "            #endif\n",
    "        #enddo\n",
    "        \n",
    "        return tree\n",
    "    #end\n",
    "\n",
    "\n",
    "    def dataSetGenerator(self):\n",
    "        \n",
    "        #print('in dataset generator')\n",
    "        N = self.N; M = self.M\n",
    "        Y = np.zeros((M,N))\n",
    "        \n",
    "        for m in range(M):\n",
    "            Y[m,:] = self.patternGenerator()\n",
    "        #end\n",
    "        \n",
    "        return Y\n",
    "    #end\n",
    "    \n",
    "#end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tree characts:\n",
      "\n",
      "   Nodes (feats) : N =  1023\n",
      "Nodes NOT leaves : n =  511\n",
      "    Nodes leaves : P =  512\n",
      "        Patterns : M =  2000\n",
      "\n",
      " <class 'numpy.ndarray'> \n",
      " [[ 1.  1. -1. ... -1. -1. -1.]\n",
      " [ 1. -1.  1. ... -1. -1. -1.]\n",
      " [ 1. -1.  1. ... -1. -1. -1.]\n",
      " ...\n",
      " [ 1. -1.  1. ... -1. -1. -1.]\n",
      " [-1.  1. -1. ... -1. -1. -1.]\n",
      " [ 1. -1.  1. ... -1. -1. -1.]]\n",
      "DataSet: 2000 data entry having 1023 features each\n",
      "\n",
      "(2000, 4)  quindi il numero di classi diverse è 4\n",
      " \n",
      "[[ 1.  1. -1. ... -1. -1. -1.]\n",
      " [ 1. -1.  1. ... -1. -1. -1.]\n",
      " [ 1. -1.  1. ... -1. -1. -1.]\n",
      " ...\n",
      " [ 1. -1.  1. ... -1. -1. -1.]\n",
      " [-1.  1. -1. ... -1. -1. -1.]\n",
      " [ 1. -1.  1. ... -1. -1. -1.]]\n",
      " \n",
      "[[1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]]\n",
      " \n",
      "Wall time: 10.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "Bf = 2\n",
    "D = 10\n",
    "M = 2000\n",
    "\n",
    "treeData = BinaryTreeDataSet(Bf,D,M)\n",
    "X = treeData.dataSetGenerator()\n",
    "print(\"\\n\",type(X),\"\\n\",X)\n",
    "\n",
    "lev = 1\n",
    "\n",
    "Y = np.eye(X.shape[0])\n",
    "print(\"DataSet: {} data entry having {} features each\\n\".format(X.shape[0], X.shape[1]))\n",
    "\n",
    "def view1D(a): # a is array\n",
    "    a = np.ascontiguousarray(a)\n",
    "    void_dt = np.dtype((np.void, a.dtype.itemsize * a.shape[1]))\n",
    "    return a.view(void_dt).ravel()\n",
    "#enddef\n",
    "\n",
    "# Get 1D view\n",
    "uppBound = Bf**(lev + 1) - 2\n",
    "\n",
    "X_ = X[:, : uppBound + 1]\n",
    "a1D = view1D(X_)\n",
    "\n",
    "# Perform broadcasting to get outer equality match\n",
    "mask = a1D[:,None]==a1D\n",
    "\n",
    "# Get indices of pairwise matches\n",
    "n = len(mask)\n",
    "mask[np.tri(n, dtype=bool)] = 0\n",
    "idx = np.argwhere(mask)\n",
    "\n",
    "# Run loop to assign equal rows in Y\n",
    "for (i,j) in zip(idx[:,0],idx[:,1]):\n",
    "    Y[j] = Y[i]\n",
    "#enddo\n",
    "\n",
    "check = np.zeros(Y.shape[0])\n",
    "listZeroCol = []\n",
    "listNoZeroCol = []\n",
    "for i in range(Y.shape[1]):\n",
    "    if (np.all( (Y[:,i] == check), axis = 0)):\n",
    "        #print(i)\n",
    "        listZeroCol.append(i)\n",
    "    #endif\n",
    "#enddo\n",
    "\n",
    "listNoZeroCol = [i for i in range(Y.shape[1]) if i not in listZeroCol]\n",
    "Y = Y[:,listNoZeroCol]\n",
    "\n",
    "print(Y.shape,\" quindi il numero di classi diverse è {}\".format(Y.shape[1]))\n",
    "print(\" \")\n",
    "print(X)\n",
    "print(\" \")\n",
    "print(Y)\n",
    "print(\" \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# DataSet import\n",
    "from math import floor\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils, plot_model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.regularizers import l1\n",
    "from keras.initializers import RandomNormal, Orthogonal\n",
    "\n",
    "# note: RandomNormal(mean = 0.0, stddev = 0.05, seed = None)\n",
    "#       Orthogonal(gain = 1.0, seed = None)\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(color_codes = True)\n",
    "\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>  Dim:  (2000, 1023) \n",
      " [[ 1. -1.  1. ... -1. -1. -1.]\n",
      " [ 1. -1.  1. ... -1. -1. -1.]\n",
      " [-1. -1.  1. ... -1. -1. -1.]\n",
      " ...\n",
      " [-1.  1. -1. ... -1. -1. -1.]\n",
      " [-1. -1.  1. ... -1. -1. -1.]\n",
      " [ 1. -1.  1. ... -1. -1. -1.]]\n",
      "<class 'numpy.ndarray'>  Dim:  (2000, 8) \n",
      " [[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "\n",
      "\n",
      "X: train dims = (1400, 1023), test dims = (600, 1023)\n",
      "\n",
      "Y: train dims = (1400, 8), test dims = (600, 8)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(type(X),\" Dim: \",X.shape,\"\\n\",X)\n",
    "print(type(Y),\" Dim: \",Y.shape,\"\\n\",Y)\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size = 0.3, random_state = 20)\n",
    "\n",
    "print(\"X: train dims = {}, test dims = {}\\n\".format(Xtrain.shape, Xtest.shape))\n",
    "print(\"Y: train dims = {}, test dims = {}\\n\".format(Ytrain.shape, Ytest.shape))\n",
    "\n",
    "M = Xtrain.shape[1]\n",
    "nCat = Ytrain.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model = Sequential()\n",
    "\n",
    "normal_init = RandomNormal(mean = 0.0, stddev = 0.05, seed = None)\n",
    "#orth_init = Orthogonal(gain = 1.0, seed = None)\n",
    "\n",
    "model.add(Dense(input_dim = M, units = 100,\n",
    "                kernel_initializer = Orthogonal(gain = 1.5, seed = None),\n",
    "                bias_initializer = RandomNormal(mean = 0.0, stddev = 0.1, seed = None),\n",
    "                activation = 'relu'))\n",
    "#model.add(Dropout(rate=0.3))\n",
    "#model.add(Dense(units = 200,\n",
    "#               kernel_initializer = Orthogonal(gain = 1.0, seed = None),\n",
    "#               bias_initializer = RandomNormal(mean = 0.0, stddev = 0.1, seed = None),\n",
    "#               activation = 'relu'))\n",
    "#model.add(Dense(activation = 'relu', units = 100))\n",
    "#model.add(Dense(activation = 'relu', units = 100))\n",
    "#model.add(Dense(activation = 'relu', units = 80))\n",
    "#model.add(Dense(activation = 'relu', units = 64))\n",
    "model.add(Dense(units = nCat, activation = 'softmax'))\n",
    "\n",
    "es1 = EarlyStopping(monitor='val_acc', mode='auto', patience = 30, verbose = 1)\n",
    "es2 = EarlyStopping(monitor='val_loss', mode='auto',patience = 20, verbose = 1)\n",
    "\n",
    "sgd = keras.optimizers.SGD(lr = 0.01, decay = 1e-6, momentum = 0.6, nesterov = True)\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = sgd, metrics = ['accuracy'])\n",
    "\n",
    "history = model.fit(Xtrain, Ytrain, validation_split = 0.1, epochs = 100, verbose = 0, callbacks = [es1,es2])\n",
    "\n",
    "\n",
    "plt.figure(figsize=(18,6))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "#plt.show()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"Model evaluation on test data: loss and accuracy\\n\",model.evaluate(Xtest,Ytest, verbose = 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine level granulometry\n",
    "\n",
    "Messo livello $L = 9$, quindi, avendo il tree 10 livelli, questa è la dinamica del learning per apprendimento del dettaglio più fine del data set, infatti è anche più dispendioso in termini di tempo.\n",
    "\n",
    "```\n",
    "Model evaluation on test data: loss and accuracy\n",
    " [0.6700157725811005, 0.9133333325386047]\n",
    "Wall time: 1min 4s\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Level9](L9.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coarse level granulometry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qui si considera il livello $L = 3$. Considerando un livello basso (più vicino al nodo `root`) si considerano **meno categorie**, infatti, come riportato nell'output della cella sopra, per la generazione di 1000 data items, tutte e sole le categorie che possono essere distinte considerando questo livello sono $8$. Si può vedere anche nell'illustrazione dell'albero binario, in quel caso quindi le distinzioni che per la quali si classifica un oggetto sono quelle di cui i nodi indicizzati da $i = 7, \\dots, 14$. \n",
    "\n",
    "Il tempo di apprendimento beneficia della grossolanità della categorizzazione, sia per quanto riguarda il numero di epoche che il tempo wallclock. Come osservato in precedenti studi (Saxe et al., 2018), si nota che k'apprendimento delle distinzioni più generali, come in questo secondo caso, avvengono più rapidamente.\n",
    "\n",
    "```\n",
    "Model evaluation on test data: loss and accuracy\n",
    " [0.009505895928790172, 0.9983333333333333]\n",
    "Wall time: 34.9 s\n",
    "```\n",
    "\n",
    "$\\quad$\n",
    "______\n",
    "\n",
    "**Remark**: Si osservi che nel caso di $L = 9$, all'epoca 20 l'accuratezza sul validation set è oscillante intorno a $0.8$, mentre qui a 10 epoche è sul $0.95$ e a 20 epoche è prossima a $1.0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Level 3](L3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.asarray(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileID = open(r'C:\\Users\\Matteo\\Desktop\\MasterThesis\\newThread\\DS_model\\weights_.pkl', 'wb')\n",
    "pickle.dump(weights, fileID)\n",
    "fileID.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileID = open(r'C:\\Users\\Matteo\\Desktop\\MasterThesis\\newThread\\DS_model\\weights_.pkl', 'rb')\n",
    "weights = pickle.load(fileID)\n",
    "fileID.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102300,)\n",
      "(100,)\n",
      "(800,)\n",
      "(8,)\n"
     ]
    }
   ],
   "source": [
    "# weights is a 4 entry list.\n",
    "# weights[0] is the  weights matrix of the input -> hidden layer\n",
    "# weights[1] is the bias vector of the input -> hidden layer\n",
    "# weights[2] is the  weights matrix of the hidden -> output layer\n",
    "# weights[3] is the bias vector of the hidden -> output layer\n",
    "\n",
    "weights = np.asarray(model.get_weights())\n",
    "\n",
    "\n",
    "wghs1 = weights[0]\n",
    "wghs1 = wghs1.flatten()\n",
    "print(wghs1.shape)\n",
    "\n",
    "bss1 = weights[1]\n",
    "bss1 = bss1.flatten()\n",
    "print(bss1.shape)\n",
    "\n",
    "wghs2 = weights[2]\n",
    "wghs2 = wghs2.flatten()\n",
    "print(wghs2.shape)\n",
    "\n",
    "bss2 = weights[3]\n",
    "bss2 = bss2.flatten()\n",
    "print(bss2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,6))\n",
    "plt.subplot(1,2,1)\n",
    "sns.distplot(wghs1, rug = True, kde = True, norm_hist = True)\n",
    "plt.xlabel(\"Weights values\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "sns.distplot(bss1, rug = True, kde = True, norm_hist = True)\n",
    "plt.xlabel(\"Biases values\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(18,6))\n",
    "plt.subplot(1,2,1)\n",
    "sns.distplot(wghs2, rug = True, kde = True, norm_hist = True)\n",
    "plt.xlabel(\"Weights values\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "sns.distplot(bss2, rug = True, kde = True, norm_hist = True)\n",
    "plt.xlabel(\"Biases values\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine level granulometry parameters distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Parameters first layer](L9_wd_L1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Parameters second layer](L9_wd_L2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coarse level granulometry parameters distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Level 3 parameters layer 1](L3_wd_L1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Level 3 parameters layer 2](L3_wd_L2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:DLenv]",
   "language": "python",
   "name": "conda-env-DLenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
